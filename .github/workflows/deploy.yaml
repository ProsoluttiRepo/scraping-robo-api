name: Deploy Scraping Service

on:
  push:
    branches:
      - main

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      # 1️⃣ Baixa o código
      - name: Checkout source code
        uses: actions/checkout@v3

      # 2️⃣ Instala SSH + rsync
      - name: Install SSH + rsync
        run: sudo apt-get update && sudo apt-get install -y sshpass openssh-client rsync

      # 3️⃣ Copia código para o servidor via rsync (sem .env)
      - name: Copy project to remote server via rsync
        run: |
          sshpass -p "${{ secrets.SSH_PASSWORD }}" rsync -avz --delete --exclude=".env" \
            -e "ssh -o StrictHostKeyChecking=no -p 22100" \
            ./ ${{ secrets.SSH_USER }}@${{ secrets.SSH_HOST }}:${{ secrets.SSH_APP_PATH }}/

      # 4️⃣ Builda e sobe os containers no servidor
      - name: Build and run with Docker Compose
        run: |
          sshpass -p "${{ secrets.SSH_PASSWORD }}" ssh -o StrictHostKeyChecking=no -p 22100 ${{ secrets.SSH_USER }}@${{ secrets.SSH_HOST }} << 'EOF'
            cd ${{ secrets.SSH_APP_PATH }}
            echo "Recriando container scraping-robo..."
            docker rm -f scraping-robo || true
            docker compose up -d --build scraping-robo
          EOF
